{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1a2f14-3fcd-4da2-b6fc-56321e149f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f34319-6477-4cda-aae8-b0496ab3acb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./flowers\\daisy\\100080576_f52e8ee070_n.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./flowers\\daisy\\10140303196_b88d3d6cec.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./flowers\\daisy\\10172379554_b296050f82_n.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./flowers\\daisy\\10172567486_2748826a8b.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./flowers\\daisy\\10172636503_21bededa75_n.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>./flowers\\tulip\\9831362123_5aac525a99_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>./flowers\\tulip\\9870557734_88eb3b9e3b_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>./flowers\\tulip\\9947374414_fdf1d0861c_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>./flowers\\tulip\\9947385346_3a8cacea02_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>./flowers\\tulip\\9976515506_d496c5e72c.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_path  label\n",
       "0       ./flowers\\daisy\\100080576_f52e8ee070_n.jpg  daisy\n",
       "1       ./flowers\\daisy\\10140303196_b88d3d6cec.jpg  daisy\n",
       "2     ./flowers\\daisy\\10172379554_b296050f82_n.jpg  daisy\n",
       "3       ./flowers\\daisy\\10172567486_2748826a8b.jpg  daisy\n",
       "4     ./flowers\\daisy\\10172636503_21bededa75_n.jpg  daisy\n",
       "...                                            ...    ...\n",
       "4312   ./flowers\\tulip\\9831362123_5aac525a99_n.jpg  tulip\n",
       "4313   ./flowers\\tulip\\9870557734_88eb3b9e3b_n.jpg  tulip\n",
       "4314   ./flowers\\tulip\\9947374414_fdf1d0861c_n.jpg  tulip\n",
       "4315   ./flowers\\tulip\\9947385346_3a8cacea02_n.jpg  tulip\n",
       "4316     ./flowers\\tulip\\9976515506_d496c5e72c.jpg  tulip\n",
       "\n",
       "[4317 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Путь до основного каталога\n",
    "base_dir = './flowers'\n",
    "\n",
    "# Список классов из папок\n",
    "flowers = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "# Сбор путей к изображениям и меток\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for flower in flowers:\n",
    "    flower_dir = os.path.join(base_dir, flower)\n",
    "    for fname in os.listdir(flower_dir):\n",
    "        image_paths.append(os.path.join(flower_dir, fname))\n",
    "        labels.append(flower) # Записываем название папки как метку класса\n",
    "\n",
    "# Создаем DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'label': labels\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a701572-aff2-4197-8de9-4a0328609aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем на тренировочную и тестовую выборки\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b82ffa2-f4b1-468e-b7c4-47721f7494d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментация данных\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=45,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703c8cfa-b6b9-4238-a7e3-a412e0aaa163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 validated image filenames belonging to 5 classes.\n",
      "Found 1296 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Создаем генераторы\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col='label',\n",
    "    target_size=(255, 255),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = (255, 255),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4d3b05-6955-4696-a2b9-de7dc544e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Содание модели\n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(255, 255, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ce8651-e5a6-45bb-8ba5-dc8130efd426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение с оптимизатором adam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "D:\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.2923 - loss: 1.6536 - val_accuracy: 0.4761 - val_loss: 1.2143\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.4647 - loss: 1.2535 - val_accuracy: 0.4946 - val_loss: 1.1384\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.5165 - loss: 1.1932 - val_accuracy: 0.5887 - val_loss: 1.0532\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.5254 - loss: 1.1250 - val_accuracy: 0.6142 - val_loss: 1.0163\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5762 - loss: 1.0442 - val_accuracy: 0.5941 - val_loss: 1.0203\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.5823 - loss: 1.0358 - val_accuracy: 0.6566 - val_loss: 0.9044\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.6210 - loss: 0.9659 - val_accuracy: 0.6420 - val_loss: 0.9223\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.6351 - loss: 0.9456 - val_accuracy: 0.6127 - val_loss: 1.0798\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.6318 - loss: 0.9627 - val_accuracy: 0.6535 - val_loss: 0.9167\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.6276 - loss: 0.9037 - val_accuracy: 0.6829 - val_loss: 0.8315\n",
      "adam: Final accuracy = 0.6829\n",
      "Обучение с оптимизатором adamw.\n",
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.2837 - loss: 1.7314 - val_accuracy: 0.4923 - val_loss: 1.2214\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.4485 - loss: 1.2747 - val_accuracy: 0.5208 - val_loss: 1.1218\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.5170 - loss: 1.1588 - val_accuracy: 0.5741 - val_loss: 1.0871\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5549 - loss: 1.1246 - val_accuracy: 0.6049 - val_loss: 1.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.5821 - loss: 1.0753 - val_accuracy: 0.6165 - val_loss: 0.9926\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.6045 - loss: 0.9913 - val_accuracy: 0.6435 - val_loss: 0.9181\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.6259 - loss: 0.9774 - val_accuracy: 0.6404 - val_loss: 0.9160\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6389 - loss: 0.9532 - val_accuracy: 0.6335 - val_loss: 0.8788\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6341 - loss: 0.9027 - val_accuracy: 0.6350 - val_loss: 0.9251\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.6360 - loss: 0.9041 - val_accuracy: 0.6798 - val_loss: 0.8097\n",
      "adamw: Final accuracy = 0.6798\n",
      "Обучение с оптимизатором sgd.\n",
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.2571 - loss: 1.5976 - val_accuracy: 0.3140 - val_loss: 1.5277\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.3247 - loss: 1.5155 - val_accuracy: 0.4228 - val_loss: 1.3588\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.3816 - loss: 1.3801 - val_accuracy: 0.5201 - val_loss: 1.2038\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.4623 - loss: 1.2751 - val_accuracy: 0.4614 - val_loss: 1.2471\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.4936 - loss: 1.2011 - val_accuracy: 0.5633 - val_loss: 1.1331\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.5060 - loss: 1.1789 - val_accuracy: 0.5301 - val_loss: 1.1222\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5246 - loss: 1.1416 - val_accuracy: 0.5224 - val_loss: 1.1355\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5310 - loss: 1.1398 - val_accuracy: 0.5355 - val_loss: 1.1938\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5484 - loss: 1.1120 - val_accuracy: 0.5764 - val_loss: 1.0958\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5442 - loss: 1.1023 - val_accuracy: 0.6065 - val_loss: 1.0240\n",
      "sgd: Final accuracy = 0.6065\n",
      "\n",
      "Results\n",
      "adam: 0.6829\n",
      "adamw: 0.6798\n",
      "sgd: 0.6065\n"
     ]
    }
   ],
   "source": [
    "optimizers = {\n",
    "    'adam': 'adam',\n",
    "    'adamw': 'adamw',\n",
    "    'sgd': 'sgd'\n",
    "}\n",
    "\n",
    "final_accuracies = {}\n",
    "\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Обучение с оптимизатором {opt_name}.\")\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs = 10,\n",
    "        validation_data=test_generator,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    final_accuracy = history.history['val_accuracy'][-1]\n",
    "    final_accuracies[opt_name] = final_accuracy\n",
    "    print(f\"{opt_name}: Final accuracy = {final_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nResults\")\n",
    "for opt_name, accuracy in final_accuracies.items():\n",
    "    print(f\"{opt_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1df0096-7cf1-4743-b022-bd213801a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 validated image filenames belonging to 5 classes.\n",
      "Found 1296 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "new_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(255, 255),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "new_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(255, 255),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20508a66-c2dc-474e-92e6-0194850451a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение с оптимизатором adam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2995 - loss: 1.7782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.3009 - loss: 1.7724 - val_accuracy: 0.4645 - val_loss: 1.2853\n",
      "Epoch 2/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.4477 - loss: 1.2446 - val_accuracy: 0.5031 - val_loss: 1.1918\n",
      "Epoch 3/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.5146 - loss: 1.1331 - val_accuracy: 0.5741 - val_loss: 1.1048\n",
      "Epoch 4/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - accuracy: 0.5440 - loss: 1.1105 - val_accuracy: 0.5617 - val_loss: 1.0580\n",
      "Epoch 5/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5536 - loss: 1.0798 - val_accuracy: 0.5934 - val_loss: 1.0185\n",
      "Epoch 6/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.6091 - loss: 0.9845 - val_accuracy: 0.6489 - val_loss: 0.9246\n",
      "Epoch 7/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.6072 - loss: 0.9830 - val_accuracy: 0.6505 - val_loss: 0.9339\n",
      "Epoch 8/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - accuracy: 0.6397 - loss: 0.9556 - val_accuracy: 0.6497 - val_loss: 0.9034\n",
      "Epoch 9/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.6360 - loss: 0.9308 - val_accuracy: 0.6798 - val_loss: 0.8377\n",
      "Epoch 10/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.6466 - loss: 0.9305 - val_accuracy: 0.6752 - val_loss: 0.8579\n",
      "Epoch 11/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.6675 - loss: 0.8987 - val_accuracy: 0.6728 - val_loss: 0.8583\n",
      "Epoch 12/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.6465 - loss: 0.9029 - val_accuracy: 0.6775 - val_loss: 0.8533\n",
      "Epoch 13/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.6849 - loss: 0.8432 - val_accuracy: 0.6790 - val_loss: 0.8633\n",
      "Epoch 14/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.6510 - loss: 0.8804 - val_accuracy: 0.6651 - val_loss: 0.8591\n",
      "Epoch 15/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.6753 - loss: 0.8323 - val_accuracy: 0.6921 - val_loss: 0.7883\n",
      "adam: Final accuracy = 0.6921\n",
      "Обучение с оптимизатором adamw.\n",
      "Epoch 1/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.2799 - loss: 1.7532 - val_accuracy: 0.4961 - val_loss: 1.2485\n",
      "Epoch 2/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.4715 - loss: 1.2549 - val_accuracy: 0.5864 - val_loss: 1.0954\n",
      "Epoch 3/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.5268 - loss: 1.1399 - val_accuracy: 0.5910 - val_loss: 1.0962\n",
      "Epoch 4/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - accuracy: 0.5744 - loss: 1.0737 - val_accuracy: 0.6312 - val_loss: 0.9854\n",
      "Epoch 5/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.5961 - loss: 1.0353 - val_accuracy: 0.6435 - val_loss: 0.9218\n",
      "Epoch 6/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.6150 - loss: 0.9989 - val_accuracy: 0.6366 - val_loss: 0.9385\n",
      "Epoch 7/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - accuracy: 0.6378 - loss: 0.9509 - val_accuracy: 0.6381 - val_loss: 0.9320\n",
      "Epoch 8/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.6185 - loss: 0.9666 - val_accuracy: 0.6636 - val_loss: 0.8715\n",
      "Epoch 9/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.6432 - loss: 0.9243 - val_accuracy: 0.6651 - val_loss: 0.8574\n",
      "Epoch 10/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.6366 - loss: 0.9091 - val_accuracy: 0.6466 - val_loss: 0.9561\n",
      "Epoch 11/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.6360 - loss: 0.9304 - val_accuracy: 0.6790 - val_loss: 0.8381\n",
      "Epoch 12/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - accuracy: 0.6707 - loss: 0.8745 - val_accuracy: 0.6728 - val_loss: 0.8516\n",
      "Epoch 13/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.6584 - loss: 0.8678 - val_accuracy: 0.6906 - val_loss: 0.8005\n",
      "Epoch 14/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.6972 - loss: 0.8280 - val_accuracy: 0.6821 - val_loss: 0.8152\n",
      "Epoch 15/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - accuracy: 0.6785 - loss: 0.8442 - val_accuracy: 0.6998 - val_loss: 0.7866\n",
      "adamw: Final accuracy = 0.6998\n",
      "\n",
      "Results\n",
      "adam: 0.6921\n",
      "adamw: 0.6998\n"
     ]
    }
   ],
   "source": [
    "optimizers = {\n",
    "    'adam': 'adam',\n",
    "    'adamw': 'adamw',\n",
    "}\n",
    "\n",
    "final_accuracies = {}\n",
    "\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Обучение с оптимизатором {opt_name}.\")\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        new_train_generator,\n",
    "        epochs = 15,\n",
    "        validation_data=new_test_generator,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    final_accuracy = history.history['val_accuracy'][-1]\n",
    "    final_accuracies[opt_name] = final_accuracy\n",
    "    print(f\"{opt_name}: Final accuracy = {final_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nResults\")\n",
    "for opt_name, accuracy in final_accuracies.items():\n",
    "    print(f\"{opt_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14442ea4-5f8f-43d4-8191-5e945fc3dd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(f'{base_dir}\\\\testOptimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc3b41-33ec-4ddf-ad45-dcae17ccc6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
